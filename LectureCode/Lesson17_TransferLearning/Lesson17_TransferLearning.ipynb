{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6gPomKPoiZ5D"
   },
   "source": [
    "# Lesson17 Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gzIuDTUxiZ5E"
   },
   "source": [
    "## Transfer Learning\n",
    "\n",
    "### 1. The Four Main Cases When Using Transfer Learning\n",
    "Transfer learning involves taking a pre-trained neural network and adapting the neural network to a new, different data set.\n",
    "\n",
    "Depending on both:\n",
    "- the size of the new data set, and\n",
    "- the similarity of the new data set to the original data set\n",
    "\n",
    "the approach for using transfer learning will be different. There are four main cases:\n",
    "1. new data set is small, new data is similar to original training data\n",
    "2. new data set is small, new data is different from original training data\n",
    "3. new data set is large, new data is similar to original training data\n",
    "4. new data set is large, new data is different from original training data\n",
    "\n",
    "|<img src = https://video.udacity-data.com/topher/2017/February/58a608ea_02-guide-how-transfer-learning-v3-01/02-guide-how-transfer-learning-v3-01.png width = 700>|\n",
    "|:---:|\n",
    "|Four Cases When Using Transfer Learning|\n",
    "\n",
    "A large data set might have one million images. A small data could have two-thousand images. The dividing line between a large data set and small data set is somewhat subjective. Overfitting is a concern when using transfer learning with a small data set.\n",
    "\n",
    "Images of dogs and images of wolves would be considered similar; the images would share common characteristics. A data set of flower images would be different from a data set of dog images.\n",
    "\n",
    "Each of the four transfer learning cases has its own approach. In the following sections, we will look at each case one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1VOwLFYViZ5F"
   },
   "source": [
    "### 2. Demonstration Network\n",
    "To explain how each situation works, we will start with a generic pre-trained convolutional neural network and explain how to adjust the network for each case. Our example network contains three convolutional layers and three fully connected layers:\n",
    "\n",
    "|<img src = https://video.udacity-data.com/topher/2017/February/58a73a2e_02-guide-how-transfer-learning-v3-02/02-guide-how-transfer-learning-v3-02.png width = 700>|\n",
    "|:---:|\n",
    "|General Overview of a Neural Network|\n",
    "\n",
    "Here is an generalized overview of what the convolutional neural network does:\n",
    "\n",
    "- the first layer will detect edges in the image\n",
    "- the second layer will detect shapes\n",
    "- the third convolutional layer detects higher level features\n",
    "\n",
    "Each transfer learning case will use the pre-trained convolutional neural network in a different way.\n",
    "\n",
    "#### Case 1: Samll Data Set, Similiar Data\n",
    "\n",
    "|<img src = https://video.udacity-data.com/topher/2017/February/58a60b70_02-guide-how-transfer-learning-v3-03/02-guide-how-transfer-learning-v3-03.png width = 700>|\n",
    "|:---:|\n",
    "|Case 1: Small Data Set with Similar Data|\n",
    "\n",
    "If the new data set is small and similar to the original training data:\n",
    "\n",
    "- slice off the end of the neural network\n",
    "- add a new fully connected layer that matches the number of classes in the new data set\n",
    "- randomize the weights of the new fully connected layer; freeze all the weights from the pre-trained network\n",
    "- train the network to update the weights of the new fully connected layer\n",
    "\n",
    "To avoid overfitting on the small data set, the weights of the original network will be held constant rather than re-training the weights.\n",
    "\n",
    "Since the data sets are similar, images from each data set will have similar higher level features. Therefore most or all of the pre-trained neural network layers already contain relevant information about the new data set and should be kept.\n",
    "\n",
    "Here's how to visualize this approach:\n",
    "\n",
    "|<img src = https://video.udacity-data.com/topher/2017/February/58a73c8d_02-guide-how-transfer-learning-v3-04/02-guide-how-transfer-learning-v3-04.png width = 700>|\n",
    "|:---:|\n",
    "|Neural Network with Small Data Set, Similar Data|\n",
    "\n",
    "#### Case 2: Small Data Set, Different Data\n",
    "|<img src = https://video.udacity-data.com/topher/2017/February/58a60eaf_02-guide-how-transfer-learning-v3-05/02-guide-how-transfer-learning-v3-05.png width = 700>|\n",
    "|:---:|\n",
    "|Case 2: Small Data Set, Different Data|\n",
    "\n",
    "If the new data set is small and different from the original training data:\n",
    "\n",
    "- slice off most of the pre-trained layers near the beginning of the network\n",
    "- add to the remaining pre-trained layers a new fully connected layer that matches the number of classes in the new data set\n",
    "- randomize the weights of the new fully connected layer; freeze all the weights from the pre-trained network\n",
    "- train the network to update the weights of the new fully connected layer\n",
    "\n",
    "Because the data set is small, overfitting is still a concern. To combat overfitting, the weights of the original neural network will be held constant, like in the first case.\n",
    "\n",
    "But the original training set and the new data set do not share higher level features. In this case, the new network will only use the layers containing lower level features.\n",
    "\n",
    "Here is how to visualize this approach:\n",
    "\n",
    "|<img src = https://video.udacity-data.com/topher/2017/February/58a73bd8_02-guide-how-transfer-learning-v3-06/02-guide-how-transfer-learning-v3-06.png width = 700>|\n",
    "|:---:|\n",
    "|Neural Network with Small Data Set, Different Data|\n",
    "\n",
    "\n",
    "#### Case 3: Large Data Set, Similar Data\n",
    "|<img src = https://video.udacity-data.com/topher/2017/February/58a6176d_02-guide-how-transfer-learning-v3-07/02-guide-how-transfer-learning-v3-07.png width = 700>|\n",
    "|:---:|\n",
    "|Case 3: Large Data Set, Similar Data|\n",
    "\n",
    "If the new data set is large and similar to the original training data:\n",
    "\n",
    "- remove the last fully connected layer and replace with a layer matching the number of classes in the new data set\n",
    "- randomly initialize the weights in the new fully connected layer\n",
    "- initialize the rest of the weights using the pre-trained weights\n",
    "- re-train the entire neural network\n",
    "\n",
    "Overfitting is not as much of a concern when training on a large data set; therefore, you can re-train all of the weights.\n",
    "\n",
    "Because the original training set and the new data set share higher level features, the entire neural network is used as well.\n",
    "\n",
    "Here is how to visualize this approach:\n",
    "\n",
    "|<img src = https://video.udacity-data.com/topher/2017/February/58a73ccd_02-guide-how-transfer-learning-v3-08/02-guide-how-transfer-learning-v3-08.png width = 700>|\n",
    "|:---:|\n",
    "|Neural Network with Large Data Set, Similar Data|\n",
    "\n",
    "#### Case 4: Large Data Set, Different Data\n",
    "\n",
    "|<img src = https://video.udacity-data.com/topher/2017/February/58a61e66_02-guide-how-transfer-learning-v3-09/02-guide-how-transfer-learning-v3-09.png width = 700>|\n",
    "|:---:|\n",
    "|Case 4: Large Data Set, Different Data|\n",
    "\n",
    "If the new data set is large and different from the original training data:\n",
    "\n",
    "- remove the last fully connected layer and replace with a layer matching the number of classes in the new data set\n",
    "- retrain the network from scratch with randomly initialized weights\n",
    "- alternatively, you could just use the same strategy as the \"large and similar\" data case\n",
    "\n",
    "Even though the data set is different from the training data, initializing the weights from the pre-trained network might make training faster. So this case is exactly the same as the case with a large, similar data set.\n",
    "\n",
    "If using the pre-trained network as a starting point does not produce a successful model, another option is to randomly initialize the convolutional neural network weights and train the network from scratch.\n",
    "\n",
    "Here is how to visualize this approach:\n",
    "\n",
    "|<img src = https://video.udacity-data.com/topher/2017/February/58a73d0d_02-guide-how-transfer-learning-v3-10/02-guide-how-transfer-learning-v3-10.png width = 700>|\n",
    "|:---:|\n",
    "|Neural Network with Large Data Set, Different Data|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KpVg47WjiZ5G"
   },
   "source": [
    "### 3. ImageNet\n",
    "ImageNet was its own competition from 2012-2017, but now it's hosted on [Kaggle](https://www.kaggle.com/c/imagenet-object-localization-challenge)! There are 1,000 different image categories between over 14 million images, so it's a great way to get involved with large datasets.\n",
    "\n",
    "Pre-training a network with the ImageNet dataset is a very common way to get a strong neural network that can be used for transfer learning. With recent versions of Keras, you can easily import a pre-trained network by using the [Keras Applications](https://keras.io/applications/) models. We'll come back to this soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kSSZsmlQiZ5H"
   },
   "source": [
    "### 4. AlexNet Architecture\n",
    "AlexNet puts the network on two GPUs, which allows for building a larger network. Although most of the calculations are done in parallel, the GPUs communicate with each other in certain layers. The [original research paper](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) on AlexNet said that parallelizing the network decreased the classification error rate by 1.7% when compared to a neural network that used half as many neurons on one GPU.\n",
    "\n",
    "|<img src = https://video.udacity-data.com/topher/2017/February/58a63da6_08-alexnet-1/08-alexnet-1.png width = 700>|\n",
    "|:---:|\n",
    "|AlexNet Architecture|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9G1N0M_NiZ5H"
   },
   "source": [
    "### 5. VGG(Visual Geometry Group at Oxford University)\n",
    "You can find the original VGG paper [here](https://arxiv.org/pdf/1409.1556.pdf).\n",
    "\n",
    "#### VGG in Keras\n",
    "As we mentioned earlier, you can fairly quickly utilize a pre-trained model with [Keras Applications](https://keras.io/applications/). VGG16 is one of the built-in models supported. There are actually two versions of VGG, VGG16 and VGG19 (where the numbers denote the number of layers included in each respective model), and you can utilize either with Keras, but we'll work with VGG16 here.\n",
    "\n",
    "```python\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "```\n",
    "\n",
    "There are two arguments to `VGG16` in this example, although there could be more or less (check out the linked documentation to see other possible arguments). The first, `weights='imagenet'`, loads the pre-trained ImageNet weights. This is actually the default argument per the documentation, so if you don't include it, you should still be loading the ImageNet weights. However, you can also specify `None` here to get random weights if you just want the architecture of VGG16; this is not suggested here since you won't get the benefit of transfer learning.\n",
    "\n",
    "The argument `include_top` is for whether you want to include the fully-connected layer at the top of the network; unless you are actually trying to classify ImageNet's 1,000 classes, you likely want to set this to `False` and add your own additional layer for the output you desire.\n",
    "\n",
    "#### Pre-processing for ImageNet weights\n",
    "There is another item to consider before jumping into using an ImageNet pre-trained model. These networks are typically pre-trained with a specific type of pre-processing, so you need to make sure to use the same pre-processing steps, or your network's outputs will likely be erratic.\n",
    "\n",
    "VGG uses 224x224 images as input, so that's another thing to consider.\n",
    "```\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "img_path = 'your_image.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2XxyueHriZ5I"
   },
   "source": [
    "#### Demo 1: Using VGG with Keras\n",
    "\n",
    "Below, you'll be able to check out the predictions from an ImageNet pre-trained VGG network with Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X8o4oUlLiZ5J"
   },
   "source": [
    "**1. Load some example images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xG6skT3UiZ5J",
    "outputId": "c1ecde4f-06da-4b81-ac2a-0d1cd81a75ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images\\\\dog_labrador.jpg', 'images\\\\elephant.jpg', 'images\\\\zebra.jpg']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load our images first, and we'll check what we have\n",
    "from glob import glob\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_paths = glob('images/*.jpg')\n",
    "\n",
    "# Print out the image paths\n",
    "print(image_paths)\n",
    "\n",
    "# View an example of an image\n",
    "example = mpimg.imread(image_paths[0])\n",
    "plt.imshow(example)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21O39pQaiZ5O"
   },
   "source": [
    "**2. Pre-process an image**   \n",
    "\n",
    "Note that the `image.load_img()` function will re-size our image to 224x224 as desired for input into this VGG16 model, so the images themselves don't have to be 224x224 to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7H_9ouOniZ5P",
    "outputId": "0e36a2ca-e9ad-4d52-cbfb-8135456e76cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Here, we'll load an image and pre-process it\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "i = 2 # Can change this to your desired image to test\n",
    "img_path = image_paths[i]\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rSbAk6OoiZ5T"
   },
   "source": [
    "**3. Load VGG16 pre-trained model**   \n",
    "\n",
    "We won't throw out the top fully-connected layer this time when we load the model, as we actually want the true ImageNet-related output. However, you'll learn how to do this in a later lab. The inference will be a little slower than you might expect here as we are not using GPU just yet.\n",
    "\n",
    "Note also the use of `decode_predictions` which will map the prediction to the class name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2vvuZBciZ5U",
    "outputId": "56e05931-0ed4-4632-f74c-5d789184408e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf1_cpu_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf1_cpu_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf1_cpu_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Predicted: [('n02391049', 'zebra', 0.9999578), ('n01798484', 'prairie_chicken', 2.7822321e-05), ('n02128925', 'jaguar', 4.685409e-06)]\n"
     ]
    }
   ],
   "source": [
    "# Note - this will likely need to download a new version of VGG16\n",
    "from keras.applications.vgg16 import VGG16, decode_predictions\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = VGG16(weights='imagenet')\n",
    "\n",
    "# Perform inference on our pre-processed image\n",
    "predictions = model.predict(x)\n",
    "\n",
    "# Check the top 3 predictions of the model\n",
    "print('Predicted:', decode_predictions(predictions, top=3)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FKniJVIniZ5X"
   },
   "source": [
    "You should mostly get the correct answers here. In our own run, it predicted a Tusker elephant with an African elephant in second place (the image is of an African elephant), correctly selected a labrador, and very confidently predicted a zebra. You can add some of your own images into the `images/` folder by clicking on the jupyter logo in the top left and see how it performs on your own examples!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ldTX_u3iZ5Y"
   },
   "source": [
    "### 5. GoogLeNet\n",
    "You can find the original GoogLeNet/Inception paper [here](https://arxiv.org/pdf/1409.4842.pdf).\n",
    "\n",
    "#### GoogLeNet/Inception in Keras\n",
    "Inception is also one of the models included in [Keras Applications](https://keras.io/applications/). Utilizing this model follows pretty much the same steps as using VGG, although this time you'll use the `InceptionV3` architecture.\n",
    "\n",
    "```python\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "model = InceptionV3(weights='imagenet', include_top=False)\n",
    "```\n",
    "\n",
    "Don't forget to perform the necessary pre-processing steps to any inputs you include! While the original Inception model used a 224x224 input like VGG, InceptionV3 actually uses a 299x299 input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bk6qGcOniZ5Y"
   },
   "source": [
    "### 6. ResNet\n",
    "[Here](https://arxiv.org/pdf/1512.03385.pdf) is the original ResNet paper, for those interested.\n",
    "\n",
    "#### ResNet in Keras\n",
    "As you may have guessed, ResNet is also a model included in Keras Applications, under `ResNet50`.\n",
    "\n",
    "```python\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "model = ResNet50(weights='imagenet', include_top=False)\n",
    "```\n",
    "\n",
    "Again, you'll need to do ImageNet-related pre-processing if you want to use the pre-trained weights for it. ResNet50 has a 224x224 input size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4A8zOgJbiZ5Z"
   },
   "source": [
    "### 7. Without Pre-trained Weights\n",
    "\n",
    "#### Using Keras Applications models without pre-trained weights\n",
    "So far, you've seen the effectiveness of models pre-trained on ImageNet weights, but what if we specify `weights=None` when we load a model? Well, you'll instead be randomly initializing the weights, as if you had built a model on your own and were starting from scratch.\n",
    "\n",
    "From our chart before, there are few situations where this might even be a potential use case - basically, when you have data that is very different from the original data. However, given the large size of the ImageNet dataset (remember, it's over 14 million images from 1,000 classes!), it's highly unlikely this is really the case - it will almost always make the most sense to start with ImageNet pre-trained weights, and only fine-tune from there\n",
    "\n",
    "|<img src = 'https://video.udacity-data.com/topher/2017/April/58e80aac_02-guide-how-transfer-learning-v3-01/02-guide-how-transfer-learning-v3-01.png' width = 700>|\n",
    "|:---:|\n",
    "|Four Use Cases of Transfer Learning|\n",
    "\n",
    "Below, let's check out what happens when we try to use a pre-made model but set the weights to `None` - this means no training has occurred yet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iVdiDax_iZ5a"
   },
   "source": [
    "#### Demo: VGG without Pre-trained Weights\n",
    "\n",
    "Below, you'll see how setting `weights=None` is equivalent to an un-trained network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DYU_G3REiZ5a"
   },
   "source": [
    "**1. Load example images and pre-process them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uxmh9SBUiZ5b"
   },
   "outputs": [],
   "source": [
    "# Load our images first, and we'll check what we have\n",
    "from glob import glob\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "image_paths = glob('images/*.jpg')\n",
    "\n",
    "i = 2 # Can change this to your desired image to test\n",
    "img_path = image_paths[i]\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a_-_sRSniZ5e"
   },
   "source": [
    "** 2.Load VGG16 model, but without pre-trained weights**\n",
    "This time, we won't use the pre-trained weights, so we'll likely get so wacky predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8V95bzLwiZ5f",
    "outputId": "1a195e1a-d442-4a4e-9549-383638173c84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n03763968', 'military_uniform', 0.0024267747), ('n02102177', 'Welsh_springer_spaniel', 0.0023948336), ('n03146219', 'cuirass', 0.002335257)]\n"
     ]
    }
   ],
   "source": [
    "# Note - this will likely need to download a new version of VGG16\n",
    "from keras.applications.vgg16 import VGG16, decode_predictions\n",
    "\n",
    "# Load VGG16 without pre-trained weights\n",
    "model = VGG16(weights=None)\n",
    "\n",
    "# Perform inference on our pre-processed image\n",
    "predictions = model.predict(x)\n",
    "\n",
    "# Check the top 3 predictions of the model\n",
    "print('Predicted:', decode_predictions(predictions, top=3)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ekFG9-S7iZ5i"
   },
   "source": [
    "When we ran each image, we got a hand-blower, a guenon (a type of African monkey) and a mink. A little bit different than the elephant, labrador and zebra they are supposed to be!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bHTn4MiOiZ5j"
   },
   "source": [
    "In the following lab, you'll get a chance to actually add layers to the end of a pre-trained model, so that you can actually use the full power of transfer learning, instead of just using it toward the 1,000 ImageNet classes as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CKYQ9kJ0iZ5j"
   },
   "source": [
    "## Lab: Transfer Learning\n",
    "In the below lab, you'll get a chance to try out a few instances of transfer learning, including both frozen and non-frozen pre-trained weights.\n",
    "\n",
    "### Frozen Weights\n",
    "Frozen weights are often used when only fine-tuning the model, as backpropagation and weight updates will not be applied to any frozen layers during training. If you have an ImageNet pre-trained model, most of the network is likely applicable to your situation, so you may only need to cut off the top fully-connected layer, freeze all other layers, and just add one or more layers at the end that are not frozen to perform some fine-tuning.\n",
    "\n",
    "There is also the option of not freezing the weights, which will start your model on the ImageNet pre-trained weights (if applicable) and then perform further training from there.\n",
    "\n",
    "An additional benefit of freezing the weights also comes in the form of memory usage and training speed - for the larger networks such as VGG, there is a substantially larger memory usage and slower speed when it needs to perform backpropagation and weight updates across all layers instead of just on a small portion of (likely smaller) layers.\n",
    "\n",
    "Note: There is a solution notebook that can be found by clicking on the Jupyter logo in the upper left of the workspace if you get stuck.\n",
    "\n",
    "Lab: Transfer Learning\n",
    "In the below lab, you'll get a chance to try out a few instances of transfer learning, including both frozen and non-frozen pre-trained weights.\n",
    "\n",
    "Frozen Weights\n",
    "Frozen weights are often used when only fine-tuning the model, as backpropagation and weight updates will not be applied to any frozen layers during training. If you have an ImageNet pre-trained model, most of the network is likely applicable to your situation, so you may only need to cut off the top fully-connected layer, freeze all other layers, and just add one or more layers at the end that are not frozen to perform some fine-tuning.\n",
    "\n",
    "There is also the option of not freezing the weights, which will start your model on the ImageNet pre-trained weights (if applicable) and then perform further training from there.\n",
    "\n",
    "An additional benefit of freezing the weights also comes in the form of memory usage and training speed - for the larger networks such as VGG, there is a substantially larger memory usage and slower speed when it needs to perform backpropagation and weight updates across all layers instead of just on a small portion of (likely smaller) layers.\n",
    "\n",
    "Note: There is a solution notebook that can be found by clicking on the Jupyter logo in the upper left of the workspace if you get stuck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fAziWDhPiZ5k"
   },
   "source": [
    "### Lab: Transfer Learning\n",
    "\n",
    "Welcome to the lab on Transfer Learning! Here, you'll get a chance to try out training a network with ImageNet pre-trained weights as a base, but with additional network layers of your own added on. You'll also get to see the difference between using frozen weights and training on all layers.\n",
    "\n",
    "#### GPU usage\n",
    "In our previous examples in this lesson, we've avoided using GPU, but this time around you'll have the option to enable it. You do not need it on to begin with, but make sure anytime you switch from non-GPU to GPU, or vice versa, that you save your notebook! If not, you'll likely be reverted to the previous checkpoint. \n",
    "\n",
    "We also suggest only using the GPU when performing the (mostly minor) training below - you'll want to conserve GPU hours for your Behavioral Cloning project coming up next!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5979,
     "status": "ok",
     "timestamp": 1599196852616,
     "user": {
      "displayName": "Juntae Park",
      "photoUrl": "",
      "userId": "01076488647874798830"
     },
     "user_tz": -540
    },
    "id": "HJXrjxghikE3",
    "outputId": "0481117b-4c2d-40d7-c9bd-dbb427c3e213"
   },
   "outputs": [],
   "source": [
    "## For COLAB\n",
    "\n",
    "# %tensorflow_version 1.x\n",
    "# import tensorflow as tf\n",
    "# print(\"Tensorflow version   : {}\".format(tf.__version__))\n",
    "\n",
    "# import keras\n",
    "# print(\"Keras version        : {}\".format(keras.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15366,
     "status": "ok",
     "timestamp": 1599196871787,
     "user": {
      "displayName": "Juntae Park",
      "photoUrl": "",
      "userId": "01076488647874798830"
     },
     "user_tz": -540
    },
    "id": "wcZk7jlAiZ5l",
    "outputId": "0a0e99e7-2c07-4264-8b8a-e768d3c31514"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set a couple flags for training - you can ignore these for now\n",
    "freeze_flag = True  # `True` to freeze layers, `False` for full training\n",
    "weights_flag = 'imagenet' # 'imagenet' or None\n",
    "preprocess_flag = True # Should be true for ImageNet pre-trained typically\n",
    "\n",
    "# Loads in InceptionV3\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# We can use smaller than the default 299x299x3 input for InceptionV3\n",
    "# which will speed up training. Keras v2.0.9 supports down to 139x139x3\n",
    "input_size = 139\n",
    "\n",
    "# Using Inception with ImageNet pre-trained weights\n",
    "inception = InceptionV3(weights=weights_flag, include_top=False,\n",
    "                        input_shape=(input_size,input_size,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eoNDzJ5XiZ5n"
   },
   "source": [
    "We'll use Inception V3 for this lab, although you can use the same techniques with any of the models in [Keras Applications](https://keras.io/applications/). Do note that certain models are only available in certain versions of Keras; this workspace uses Keras v2.0.9, for which you can see the available models [here](https://faroit.github.io/keras-docs/2.0.9/applications/).\n",
    "\n",
    "In the above, we've set Inception to use an `input_shape` of 139x139x3 instead of the default 299x299x3. This will help us to speed up our training a bit later (and we'll actually be upsampling from smaller images, so we aren't losing data here). In order to do so, we also must set `include_top` to `False`, which means the final fully-connected layer with 1,000 nodes for each ImageNet class is dropped, as well as a Global Average Pooling layer.\n",
    "\n",
    "### Pre-trained with frozen weights\n",
    "To start, we'll see how an ImageNet pre-trained model with all weights frozen in the InceptionV3 model performs. We will also drop the end layer and append new layers onto it, although you could do this in different ways (not drop the end and add new layers, drop more layers than we will here, etc.).\n",
    "\n",
    "You can freeze layers by setting `layer.trainable` to False for a given `layer`. Within a `model`, you can get the list of layers with `model.layers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 738,
     "status": "ok",
     "timestamp": 1599196874453,
     "user": {
      "displayName": "Juntae Park",
      "photoUrl": "",
      "userId": "01076488647874798830"
     },
     "user_tz": -540
    },
    "id": "BVuDOrNAiZ5o"
   },
   "outputs": [],
   "source": [
    "if freeze_flag == True:\n",
    "    ## TODO: Iterate through the layers of the Inception model\n",
    "    ##       loaded above and set all of them to have trainable = False\n",
    "    for layer in inception.layers:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OWHVQUs7iZ5r"
   },
   "source": [
    "### Dropping layers\n",
    "You can drop layers from a model with `model.layers.pop()`. Before you do this, you should check out what the actual layers of the model are with Keras's `.summary()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 674,
     "status": "ok",
     "timestamp": 1599196876384,
     "user": {
      "displayName": "Juntae Park",
      "photoUrl": "",
      "userId": "01076488647874798830"
     },
     "user_tz": -540
    },
    "id": "K47O9pdoiZ5r",
    "outputId": "edad18b9-454d-4343-b1e3-d4b3ba91eb8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 139, 139, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 69, 69, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 69, 69, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 69, 69, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 67, 67, 32)   9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 67, 67, 32)   96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 67, 67, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 67, 67, 64)   18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 67, 67, 64)   192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 67, 67, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 33, 33, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 33, 33, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 33, 33, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 33, 33, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 31, 31, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 31, 31, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 31, 31, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 15, 15, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 15, 15, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 15, 15, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 15, 15, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 15, 15, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 15, 15, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 15, 15, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 15, 15, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 15, 15, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 15, 15, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 15, 15, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 15, 15, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 15, 15, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 15, 15, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 15, 15, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 15, 15, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 15, 15, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 15, 15, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 15, 15, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 15, 15, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 15, 15, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 15, 15, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 15, 15, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 15, 15, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 15, 15, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 15, 15, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 15, 15, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 15, 15, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 15, 15, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 15, 15, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 15, 15, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 15, 15, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 15, 15, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 15, 15, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 15, 15, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 15, 15, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 15, 15, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 15, 15, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 15, 15, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 15, 15, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 15, 15, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 15, 15, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 15, 15, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 15, 15, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 15, 15, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 15, 15, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 15, 15, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 15, 15, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 15, 15, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 15, 15, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 15, 15, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 15, 15, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 15, 15, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 15, 15, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 15, 15, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 15, 15, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 15, 15, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 15, 15, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 15, 15, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 15, 15, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 15, 15, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 15, 15, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 15, 15, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 15, 15, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 15, 15, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 15, 15, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 15, 15, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 15, 15, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 15, 15, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 15, 15, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 15, 15, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 15, 15, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 15, 15, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 15, 15, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 15, 15, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 15, 15, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 7, 7, 96)     82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 7, 7, 384)    1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 7, 7, 96)     288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 7, 7, 384)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 7, 7, 96)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 7, 7, 128)    114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 7, 7, 128)    114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 7, 7, 128)    384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 7, 7, 128)    384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 7, 7, 128)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 7, 7, 128)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 7, 7, 192)    172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 7, 7, 192)    172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 7, 7, 192)    576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 7, 7, 192)    576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 7, 7, 192)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 7, 7, 192)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 160)    179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 160)    179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 160)    480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 160)    480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 160)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 160)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 192)    215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 192)    215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 7, 7, 192)    576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 192)    576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 192)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 192)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 160)    179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 7, 7, 160)    179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 7, 7, 160)    480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 7, 7, 160)    480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 7, 7, 160)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 7, 7, 160)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 7, 7, 192)    215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 7, 7, 192)    215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 192)    576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 7, 7, 192)    576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 7, 7, 192)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 7, 7, 192)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 192)    258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 7, 7, 192)    258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 7, 7, 192)    258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 7, 7, 192)    576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 7, 7, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 7, 7, 192)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 7, 7, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 3, 3, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 3, 3, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 3, 3, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 3, 3, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 3, 3, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 3, 3, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 3, 3, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 3, 3, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 3, 3, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 3, 3, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 3, 3, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 3, 3, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 3, 3, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 3, 3, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 3, 3, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 3, 3, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 3, 3, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 3, 3, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 3, 3, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 3, 3, 448)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 3, 3, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 3, 3, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 3, 3, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 3, 3, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 3, 3, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 3, 3, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 3, 3, 320)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 3, 3, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 3, 3, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 3, 3, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 3, 3, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3, 3, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 3, 3, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## TODO: Use the model summary function to see all layers in the\n",
    "##       loaded Inception model\n",
    "inception.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6AkDAtZQiZ5u"
   },
   "source": [
    "In a normal Inception network, you would see from the model summary that the last two layers were a global average pooling layer, and a fully-connected \"Dense\" layer. However, since we set `include_top` to `False`, both of these get dropped. If you otherwise wanted to drop additional layers, you would use:\n",
    "\n",
    "```\n",
    "inception.layers.pop()\n",
    "```\n",
    "\n",
    "Note that `pop()` works from the end of the model backwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BSTrXHf_iZ5v"
   },
   "source": [
    "It's important to note two things here:\n",
    "1. How many layers you drop is up to you, typically. We dropped the final two already by setting `include_top` to False in the original loading of the model, but you could instead just run `pop()` twice to achieve similar results. (*Note:* Keras requires us to set `include_top` to False in order to change the `input_shape`.) Additional layers could be dropped by additional calls to `pop()`.\n",
    "2. If you make a mistake with `pop()`, you'll want to reload the model. If you use it multiple times, the model will continue to drop more and more layers, so you may need to check `model.summary()` again to check your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hPhtYXN3iZ5v"
   },
   "source": [
    "### Adding new layers\n",
    "\n",
    "Now, you can start to add your own layers. While we've used Keras's `Sequential` model before for simplicity, we'll actually use the [Model API](https://keras.io/models/model/) this time. This functions a little differently, in that instead of using `model.add()`, you explicitly tell the model which previous layer to attach to the current layer. This is useful if you want to use more advanced concepts like [skip layers](https://en.wikipedia.org/wiki/Residual_neural_network), for instance (which were used heavily in ResNet).\n",
    "\n",
    "For example, if you had a previous layer named `inp`:\n",
    "```\n",
    "x = Dropout(0.2)(inp)\n",
    "```\n",
    "is how you would attach a new dropout layer `x`, with it's input coming from a layer with the variable name `inp`.\n",
    "\n",
    "We are going to use the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html), which consists of 60,000 32x32 images of 10 classes. We need to use Keras's `Input` function to do so, and then we want to re-size the images up to the `input_size` we specified earlier (139x139)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3988,
     "status": "ok",
     "timestamp": 1599196889838,
     "user": {
      "displayName": "Juntae Park",
      "photoUrl": "",
      "userId": "01076488647874798830"
     },
     "user_tz": -540
    },
    "id": "Eaca3uNhiZ5w"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Lambda\n",
    "%tensorflow_version 1.x\n",
    "import tensorflow as tf\n",
    "\n",
    "# Makes the input placeholder layer 32x32x3 for CIFAR-10\n",
    "cifar_input = Input(shape=(32,32,3))\n",
    "\n",
    "# Re-sizes the input with Kera's Lambda layer & attach to cifar_input\n",
    "resized_input = Lambda(lambda image: tf.image.resize_images( \n",
    "    image, (input_size, input_size)))(cifar_input)\n",
    "\n",
    "# Feeds the re-sized input into Inception model\n",
    "# You will need to update the model name if you changed it earlier!\n",
    "inp = inception(resized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 741,
     "status": "ok",
     "timestamp": 1599196893957,
     "user": {
      "displayName": "Juntae Park",
      "photoUrl": "",
      "userId": "01076488647874798830"
     },
     "user_tz": -540
    },
    "id": "wEc2pMq7iZ5z"
   },
   "outputs": [],
   "source": [
    "# Imports fully-connected \"Dense\" layers & Global Average Pooling\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "## TODO: Setting `include_top` to False earlier also removed the\n",
    "##       GlobalAveragePooling2D layer, but we still want it.\n",
    "##       Add it here, and make sure to connect it to the end of Inception\n",
    "x = GlobalAveragePooling2D()(inp)\n",
    "\n",
    "## TODO: Create two new fully-connected layers using the Model API\n",
    "##       format discussed above. The first layer should use `out`\n",
    "##       as its input, along with ReLU activation. You can choose\n",
    "##       how many nodes it has, although 512 or less is a good idea.\n",
    "##       The second layer should take this first layer as input, and\n",
    "##       be named \"predictions\", with Softmax activation and \n",
    "##       10 nodes, as we'll be using the CIFAR10 dataset.\n",
    "x = Dense(512, activation = 'relu')(x)\n",
    "predictions = Dense(10, activation = 'softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o16KLmp4iZ55"
   },
   "source": [
    "We're almost done with our new model! Now we just need to use the actual Model API to create the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 691,
     "status": "ok",
     "timestamp": 1599196903134,
     "user": {
      "displayName": "Juntae Park",
      "photoUrl": "",
      "userId": "01076488647874798830"
     },
     "user_tz": -540
    },
    "id": "I25zmZj6iZ56",
    "outputId": "acfde48c-63f8-44c1-a839-8d4aafc38f10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 139, 139, 3)       0         \n",
      "_________________________________________________________________\n",
      "inception_v3 (Model)         (None, 3, 3, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 22,857,002\n",
      "Trainable params: 1,054,218\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Imports the Model API\n",
    "from keras.models import Model\n",
    "\n",
    "# Creates the model, assuming your final layer is named \"predictions\"\n",
    "model = Model(inputs=cifar_input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Check the summary of this new model to confirm the architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vXuCIs2CiZ59"
   },
   "source": [
    "Great job creating a new model architecture from Inception! Notice how this method of adding layers before InceptionV3 and appending to the end of it made InceptionV3 condense down into one line in the summary; if you use the Inception model's normal input (which you could gather from `inception.layers.input`), it would instead show all the layers like before.\n",
    "\n",
    "Most of the rest of the code in the notebook just goes toward loading our data, pre-processing it, and starting our training in Keras, although there's one other good point to make here - Keras callbacks.\n",
    "\n",
    "### Keras Callbacks\n",
    "Keras [callbacks](https://keras.io/callbacks/) allow you to gather and store additional information during training, such as the best model, or even stop training early if the validation accuracy has stopped improving. These methods can help to avoid overfitting, or avoid other issues.\n",
    "\n",
    "There's two key callbacks to mention here, `ModelCheckpoint` and `EarlyStopping`. As the names may suggest, model checkpoint saves down the best model so far based on a given metric, while early stopping will end training before the specified number of epochs if the chosen metric no longer improves after a given amount of time.\n",
    "\n",
    "To set these callbacks, you could do the following:\n",
    "```\n",
    "checkpoint = ModelCheckpoint(filepath=save_path, monitor='val_loss', save_best_only=True)\n",
    "```\n",
    "This would save a model to a specified `save_path`, based on validation loss, and only save down the best models. If you set `save_best_only` to `False`, every single epoch will save down another version of the model.\n",
    "```\n",
    "stopper = EarlyStopping(monitor='val_acc', min_delta=0.0003, patience=5)\n",
    "```\n",
    "This will monitor validation accuracy, and if it has not decreased by more than 0.0003 from the previous best validation accuracy for 5 epochs, training will end early.\n",
    "\n",
    "\n",
    "You still need to actually feed these callbacks into `fit()` when you train the model (along with all other relevant data to feed into `fit`):\n",
    "```\n",
    "model.fit(callbacks=[checkpoint, stopper])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OfgwGXlriZ59"
   },
   "source": [
    "## GPU time\n",
    "\n",
    "The rest of the notebook will give you the code for training, so you can turn on the GPU at this point - but first, **make sure to save your jupyter notebook**. Once the GPU is turned on, it will load whatever your last notebook checkpoint is. \n",
    "\n",
    "While we suggest reading through the code below to make sure you understand it, you can otherwise go ahead and select *Cell > Run All* (or *Kernel > Restart & Run All* if already using GPU) to run through all cells in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5029,
     "status": "ok",
     "timestamp": 1599196919940,
     "user": {
      "displayName": "Juntae Park",
      "photoUrl": "",
      "userId": "01076488647874798830"
     },
     "user_tz": -540
    },
    "id": "D05ipfiYiZ5-",
    "outputId": "6ac46f30-2871-4b21-bf65-0531d0f98746"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "(X_train, y_train), (X_val, y_val) = cifar10.load_data()\n",
    "\n",
    "# One-hot encode the labels\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot_train = label_binarizer.fit_transform(y_train)\n",
    "y_one_hot_val = label_binarizer.fit_transform(y_val)\n",
    "\n",
    "# Shuffle the training & test data\n",
    "X_train, y_one_hot_train = shuffle(X_train, y_one_hot_train)\n",
    "X_val, y_one_hot_val = shuffle(X_val, y_one_hot_val)\n",
    "\n",
    "# We are only going to use the first 10,000 images for speed reasons\n",
    "# And only the first 2,000 images from the test set\n",
    "X_train = X_train[:10000]\n",
    "y_one_hot_train = y_one_hot_train[:10000]\n",
    "X_val = X_val[:2000]\n",
    "y_one_hot_val = y_one_hot_val[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VzYjVYQBiZ6B"
   },
   "source": [
    "You can check out Keras's [ImageDataGenerator documentation](https://faroit.github.io/keras-docs/2.0.9/preprocessing/image/) for more information on the below - you can also add additional image augmentation through this function, although we are skipping that step here so you can potentially explore it in the upcoming project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 691,
     "status": "ok",
     "timestamp": 1599196936354,
     "user": {
      "displayName": "Juntae Park",
      "photoUrl": "",
      "userId": "01076488647874798830"
     },
     "user_tz": -540
    },
    "id": "PBRhIL4CiZ6C"
   },
   "outputs": [],
   "source": [
    "# Use a generator to pre-process our images for ImageNet\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "if preprocess_flag == True:\n",
    "    datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "    val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "else:\n",
    "    datagen = ImageDataGenerator()\n",
    "    val_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 104297,
     "status": "ok",
     "timestamp": 1599197043562,
     "user": {
      "displayName": "Juntae Park",
      "photoUrl": "",
      "userId": "01076488647874798830"
     },
     "user_tz": -540
    },
    "id": "1YlgJXJqiZ6E",
    "outputId": "12d92ac4-9529-4268-c6b5-2df126cd1187"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/5\n",
      "313/312 [==============================] - 28s 90ms/step - loss: 1.2806 - accuracy: 0.5681 - val_loss: 0.4499 - val_accuracy: 0.6570\n",
      "Epoch 2/5\n",
      "313/312 [==============================] - 18s 59ms/step - loss: 0.9635 - accuracy: 0.6686 - val_loss: 1.3283 - val_accuracy: 0.7000\n",
      "Epoch 3/5\n",
      "313/312 [==============================] - 18s 59ms/step - loss: 0.8818 - accuracy: 0.6956 - val_loss: 1.3337 - val_accuracy: 0.6940\n",
      "Epoch 4/5\n",
      "313/312 [==============================] - 19s 59ms/step - loss: 0.8303 - accuracy: 0.7090 - val_loss: 1.7292 - val_accuracy: 0.7285\n",
      "Epoch 5/5\n",
      "313/312 [==============================] - 19s 59ms/step - loss: 0.7738 - accuracy: 0.7330 - val_loss: 0.5852 - val_accuracy: 0.7210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fd2084cb358>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "# Note: we aren't using callbacks here since we only are using 5 epochs to conserve GPU time\n",
    "model.fit_generator(datagen.flow(X_train, y_one_hot_train, batch_size=batch_size), \n",
    "                    steps_per_epoch=len(X_train)/batch_size, epochs=epochs, verbose=1, \n",
    "                    validation_data=val_datagen.flow(X_val, y_one_hot_val, batch_size=batch_size),\n",
    "                    validation_steps=len(X_val)/batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "92O9vGAqiZ6H"
   },
   "source": [
    "As you may have noticed, CIFAR-10 is a fairly tough dataset. However, given that we are only training on a small subset of the data, only training for five epochs, and not using any image augmentation, the results are still fairly impressive!\n",
    "\n",
    "We achieved ~70% validation accuracy here, although your results may vary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "As-sY91JiZ6H"
   },
   "source": [
    "## [Optional] Test without frozen weights, or by training from scratch.\n",
    "\n",
    "Since the majority of the model was frozen above, training speed is pretty quick. You may also want to check out the training speed, as well as final accuracy, if you don't freeze the weights. Note that this can be fairly slow, so we're marking this as optional in order to conserve GPU time. \n",
    "\n",
    "If you do want to see the results from doing so, go back to the first code cell and set `freeze_flag` to `False`. If you want to completely train from scratch without ImageNet pre-trained weights, follow the previous step as well as setting `weights_flag` to `None`. Then, go to *Kernel > Restart & Run All*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KyuKYFdwiZ6I"
   },
   "source": [
    "## Comparison\n",
    "\n",
    "So that you don't use up your GPU time, we've tried out these results ourselves as well.\n",
    "\n",
    "Training Mode | Val Acc @ 1 epoch | Val Acc @ 5 epoch | Time per epoch\n",
    "---- | :----: | :----: | ----:\n",
    "Frozen weights | 65.5% | 70.3% | 50 seconds\n",
    "Unfrozen weights | 50.6% | 71.6% | 142 seconds\n",
    "No pre-trained weights | 19.2% | 39.2% | 142 seconds\n",
    "\n",
    "From the above, we can see that the pre-trained model with frozen weights actually began converging the fastest (already at 65.5% after 1 epoch), while the model re-training from the pre-trained weights slightly edged it out after 5 epochs.\n",
    "\n",
    "However, this does not tell the whole story - the training accuracy was substantially higher, nearing 87% for the unfrozen weights model. It actually began overfit the data much more under this method. We would likely be able to counteract some of this issue by using data augmentation. On the flip side, the model using frozen weights could also have been improved by actually only freezing a portion of the weights; some of these are likely more specific to ImageNet classes as it gets later in the network, as opposed to the simpler features extracted early in the network.\n",
    "\n",
    "### The Power of Transfer Learning\n",
    "Comparing the last line to the other two really shows the power of transfer learning. After five epochs, a model without ImageNet pre-training had only achieved 39.2% accuracy, compared to over 70% for the other two. As such, pre-training the network has saved substantial time, especially given the additional training time needed when the weights are not frozen.\n",
    "\n",
    "There is also evidence found in various research that pre-training on ImageNet weights will result in a higher overall accuracy than completely training from scratch, even when using a substantially different dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources on Deep Learning\n",
    "Nice work reaching the end of the deep learning content! While you still have the project left to do here, we're also providing some additional resources and recent research on the topic that you can come back to if you have time later on.\n",
    "\n",
    "Reading research papers is a great way to get exposure to the latest and greatest in the field, as well as expand your learning. However, just like the project ahead, it's often best to learn by doing - if you find a paper that really excites you, try to implement it (or even something better) yourself!\n",
    "\n",
    "### Optional Reading\n",
    "All of these are completely optional reading - you could spend hours reading through the entirety of these! We suggest moving onto the project first so you have what you’ve learned fresh on your mind, before coming back to check these out.\n",
    "\n",
    "We've categorized these papers to hopefully help you narrow down which ones might be of interest, as well as highlighted a couple key reads by category by including their Abstract section, which summarizes the paper.\n",
    "\n",
    "---\n",
    "\n",
    "### Behavioral Cloning\n",
    "The below paper shows one of the techniques Waymo has researched using imitation learning (aka behavioral cloning) to drive a car.\n",
    "\n",
    "[ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst](https://arxiv.org/abs/1812.03079) by M. Bansal, A. Krizhevsky and A. Ogale\n",
    "\n",
    " - **Abstract**: Our goal is to train a policy for autonomous driving via imitation learning that is robust enough to drive a real vehicle. We find that standard behavior cloning is insufficient for handling complex driving scenarios, even when we leverage a perception system for preprocessing the input and a controller for executing the output on the car: 30 million examples are still not enough. We propose exposing the learner to synthesized data in the form of perturbations to the expert's driving, which creates interesting situations such as collisions and/or going off the road. Rather than purely imitating all data, we augment the imitation loss with additional losses that penalize undesirable events and encourage progress -- the perturbations then provide an important signal for these losses and lead to robustness of the learned model. We show that the ChauffeurNet model can handle complex situations in simulation, and present ablation experiments that emphasize the importance of each of our proposed changes and show that the model is responding to the appropriate causal factors. Finally, we demonstrate the model driving a car in the real world.\n",
    "\n",
    "---\n",
    "\n",
    "### Object Detection and Tracking\n",
    "The below papers include various deep learning-based approaches to 2D and 3D object detection and tracking.\n",
    "\n",
    "[SSD: Single Shot MultiBox Detector](https://arxiv.org/abs/1512.02325) by W. Liu, et. al.\n",
    "\n",
    "- **Abstract**: We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction time, the network generates scores for the presence of each object category in each default box and produces adjustments to the box to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. Our SSD model is simple relative to methods that require object proposals because it completely eliminates proposal generation and subsequent pixel or feature resampling stage and encapsulates all computation in a single network. [...] Experimental results [...] confirm that SSD has comparable accuracy to methods that utilize an additional object proposal step and is much faster, while providing a unified framework for both training and inference. Compared to other single stage methods, SSD has much better accuracy, even with a smaller input image size. [...]\n",
    "\n",
    "[VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection](https://arxiv.org/abs/1711.06396) by Y. Zhou and O. Tuzel\n",
    "\n",
    "- **Abstract**: Accurate detection of objects in 3D point clouds is a central problem in many applications, such as autonomous navigation, housekeeping robots, and augmented/virtual reality. To interface a highly sparse LiDAR point cloud with a region proposal network (RPN), most existing efforts have focused on hand-crafted feature representations, for example, a bird's eye view projection. In this work, we remove the need of manual feature engineering for 3D point clouds and propose VoxelNet, a generic 3D detection network that unifies feature extraction and bounding box prediction into a single stage, end-to-end trainable deep network. [...] Experiments on the KITTI car detection benchmark show that VoxelNet outperforms the state-of-the-art LiDAR based 3D detection methods by a large margin. Furthermore, our network learns an effective discriminative representation of objects with various geometries, leading to encouraging results in 3D detection of pedestrians and cyclists, based on only LiDAR.\n",
    "\n",
    "[Fast and Furious: Real Time End-to-End 3D Detection, Tracking and Motion Forecasting with a Single Convolutional Net](http://openaccess.thecvf.com/content_cvpr_2018/papers/Luo_Fast_and_Furious_CVPR_2018_paper.pdf) by W. Luo, et. al.\n",
    "\n",
    "- **Abstract**: In this paper we propose a novel deep neural network that is able to jointly reason about 3D detection, tracking and motion forecasting given data captured by a 3D sensor. By jointly reasoning about these tasks, our holistic approach is more robust to occlusion as well as sparse data at range. Our approach performs 3D convolutions across space and time over a bird’s eye view representation of the 3D world, which is very efficient in terms of both memory and computation. Our experiments on a new very large scale dataset captured in several north american cities, show that we can outperform the state-of-the-art by a large margin. Importantly, by sharing computation we can perform all tasks in as little as 30 ms.\n",
    "\n",
    "---\n",
    "\n",
    "### Semantic Segmentation\n",
    "The below paper concerns a technique called semantic segmentation, where each pixel of an image gets classified individually!\n",
    "\n",
    "[SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation](https://arxiv.org/abs/1511.00561) by V. Badrinarayanan, A. Kendall and R. Cipolla\n",
    "\n",
    "- **Abstract**: We present a novel and practical deep fully convolutional neural network architecture for semantic pixel-wise segmentation termed SegNet. [...] The novelty of SegNet lies in the manner in which the decoder upsamples its lower resolution input feature map(s). Specifically, the decoder uses pooling indices computed in the max-pooling step of the corresponding encoder to perform non-linear upsampling. This eliminates the need for learning to upsample. The upsampled maps are sparse and are then convolved with trainable filters to produce dense feature maps. We compare our proposed architecture with the widely adopted FCN and also with the well known DeepLab-LargeFOV, DeconvNet architectures. This comparison reveals the memory versus accuracy trade-off involved in achieving good segmentation performance. [...] We show that SegNet provides good performance with competitive inference time and more efficient inference memory-wise as compared to other architectures. [...]\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lesson17_TransferLearning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
