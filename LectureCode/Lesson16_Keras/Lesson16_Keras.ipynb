{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson16 Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks in Keras\n",
    "Here are some core concepts you need to know for working with Keras. All Keras exercises will be performed in JUPYTER workspaces, using python 3.5, Tensorflow 1.3, and [Keras](https://keras.io/) 2.09. More information on using JUPYTER in workspaces, can be found earlier in the term in the Workspaces lesson.\n",
    "\n",
    "### Sequential Model\n",
    "```python\n",
    "    from keras.models import Sequential\n",
    "\n",
    "    # Create the Sequential model\n",
    "    model = Sequential()\n",
    "```\n",
    "\n",
    "The [keras.models.Sequential](https://keras.io/api/models/sequential/) class is a wrapper for the neural network model. It provides common functions like `fit()`, `evaluate()`, and `compile()`. We'll cover these functions as we get to them. Let's start looking at the layers of the model.\n",
    "\n",
    "See the documentation for `keras.models.Sequential` in Keras 2.09 [here](https://faroit.com/keras-docs/2.0.9/models/sequential/).\n",
    "\n",
    "### Layers\n",
    "A Keras layer is just like a neural network layer. There are fully connected layers, max pool layers, and activation layers. You can add a layer to the model using the model's 'add()' function. For example, a simple model would look like this:\n",
    "```python\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers.core import Dense, Activation, Flatten\n",
    "\n",
    "    # Create the Sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    #1st Layer - Add a flatten layer\n",
    "    model.add(Flatten(input_shape=(32, 32, 3)))\n",
    "\n",
    "    #2nd Layer - Add a fully connected layer\n",
    "    model.add(Dense(100))\n",
    "\n",
    "    #3rd Layer - Add a ReLU activation layer\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #4th Layer - Add a fully connected layer\n",
    "    model.add(Dense(60))\n",
    "\n",
    "    #5th Layer - Add a ReLU activation layer\n",
    "    model.add(Activation('relu'))\n",
    "```\n",
    "\n",
    "Keras will automatically infer the shape of all layers after the first layer. This means you only have to set the input dimensions for the first layer.\n",
    "\n",
    "The first layer from above, `model.add(Flatten(input_shape=(32, 32, 3)))`, sets the input dimension to (32, 32, 3) and output dimension to (3072=32 x 32 x 3). The second layer takes in the output of the first layer and sets the output dimensions to (100). This chain of passing output to the next layer continues until the last layer, which is the output of the model.\n",
    "\n",
    "### Quiz\n",
    "In this quiz you will build a multi-layer feedforward neural network to classify traffic sign images using Keras.\n",
    "\n",
    "1. Set the first layer to a Flatten() layer with the input_shape set to (32, 32, 3).\n",
    "2. Set the second layer to a Dense() layer with an output width of 128.\n",
    "3. Use a ReLU activation function after the second layer.\n",
    "4. Set the output layer width to 5, because for this data set there are only 5 classes.\n",
    "5. Use a softmax activation function after the output layer.\n",
    "6. Train the model for 3 epochs. You should be able to get over 50% training accuracy.\n",
    "\n",
    "To get started, review the Keras documentation about models and layers. The Keras example of a [Multi-Layer Perceptron](https://github.com/keras-team/keras/blob/master/examples/mnist_mlp.py) network is similar to what you need to do here. Use that as a guide, but keep in mind that there are a number of differences.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (100, 32, 32, 3)\n",
      "y_train shape : (100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# Load pickled data\n",
    "with open('small_train_traffic.p', mode='rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# split data\n",
    "X_train, y_train = data['features'], data['labels']\n",
    "\n",
    "print(\"X_train shape : {}\".format(X_train.shape))\n",
    "print(\"y_train shape : {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf1_cpu_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# Setup Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "\n",
    "# TODO: Build the Fully Connected Neural Network in Keras Here\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(32, 32, 3)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.layers[0].input_shape == (None, 32, 32, 3)) & \\\n",
    "                          (model.layers[1].output_shape == (None, 128)) & \\\n",
    "                          (model.layers[1].activation == keras.activations.relu) & \\\n",
    "                          (model.layers[2].output_shape == (None, 5)) & \\\n",
    "                          (model.layers[2].activation == keras.activations.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf1_cpu_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/3\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.1880 - acc: 0.4625 - val_loss: 0.7885 - val_acc: 0.6500\n",
      "Epoch 2/3\n",
      "80/80 [==============================] - 0s 255us/step - loss: 0.7769 - acc: 0.5500 - val_loss: 0.6223 - val_acc: 0.7000\n",
      "Epoch 3/3\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.7044 - acc: 0.6000 - val_loss: 0.5522 - val_acc: 0.8000\n"
     ]
    }
   ],
   "source": [
    "# TODO: change the number of training epochs to 3\n",
    "history = model.fit(X_normalized, y_one_hot, epochs=3, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice work!\n",
      "Looks good!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "### Be sure to run all cells above before running this cell ###\n",
    "import grader_dnn as grader\n",
    "\n",
    "try:\n",
    "    grader.run_grader(model, history)\n",
    "except Exception as err:\n",
    "    print(str(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutions\n",
    "1. Build from the previous network.\n",
    "2. Add a [convolutional layer](https://keras.io/api/layers/convolution_layers/#convolution2d) with 32 filters, a 3x3 kernel, and valid padding before the flatten layer.\n",
    "3. Add a ReLU activation after the convolutional layer.\n",
    "4. Train for 3 epochs again, should be able to get over 50% accuracy.\n",
    "Hint: The Keras example of a [convolutional neural network](https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py) for MNIST would be a good example to review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load pickled data\n",
    "with open('small_train_traffic.p', mode='rb') as f:\n",
    "    data = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_train, y_train= data['features'], data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build Convolutional Neural Network in Keras Here\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), padding = 'valid', activation = 'relu', input_shape = (32, 32, 3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(5, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/3\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 1.8516 - acc: 0.3500 - val_loss: 1.1159 - val_acc: 0.8500\n",
      "Epoch 2/3\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.0901 - acc: 0.8000 - val_loss: 0.5241 - val_acc: 0.8000\n",
      "Epoch 3/3\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.7647 - acc: 0.6875 - val_loss: 0.2683 - val_acc: 0.8500\n"
     ]
    }
   ],
   "source": [
    "# compile and train model\n",
    "# Training for 3 epochs should result in > 50% accuracy\n",
    "model.compile('adam', 'categorical_crossentropy', ['acc'])\n",
    "history = model.fit(X_normalized, y_one_hot, epochs=3, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice work!\n",
      "Looks good!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "### Be sure to run all cells above before running this cell ###\n",
    "import grader_cnn as grader\n",
    "\n",
    "try:\n",
    "    grader.run_grader(model, history)\n",
    "except Exception as err:\n",
    "    print(str(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling\n",
    "1. Build from the previous network\n",
    "2. Add a 2x2 [max pooling layer](https://keras.io/api/layers/pooling_layers/#maxpooling2d) immediately following your convolutional layer.\n",
    "3. Train for 3 epochs again. You should be able to get over 50% training accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load pickled data\n",
    "with open('small_train_traffic.p', mode='rb') as f:\n",
    "    data = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_train, y_train= data['features'], data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf1_cpu_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Build Convolutional Neural Network in Keras Here\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), padding = 'valid', activation = 'relu', input_shape = (32, 32, 3)))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(5, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/3\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 1.3827 - acc: 0.3750 - val_loss: 0.7314 - val_acc: 0.6500\n",
      "Epoch 2/3\n",
      "80/80 [==============================] - 0s 843us/step - loss: 0.8239 - acc: 0.5000 - val_loss: 0.5109 - val_acc: 0.8500\n",
      "Epoch 3/3\n",
      "80/80 [==============================] - 0s 726us/step - loss: 0.5771 - acc: 0.8000 - val_loss: 0.4375 - val_acc: 0.8500\n"
     ]
    }
   ],
   "source": [
    "# compile and train model\n",
    "# Training for 3 epochs should result in > 50% accuracy\n",
    "model.compile('adam', 'categorical_crossentropy', ['acc'])\n",
    "history = model.fit(X_normalized, y_one_hot, epochs=3, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice work!\n",
      "Looks good!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "### Be sure to run all cells above before running this cell ###\n",
    "import grader_pool as grader\n",
    "\n",
    "try:\n",
    "    grader.run_grader(model, history)\n",
    "except Exception as err:\n",
    "    print(str(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "1. Build from the previous network.\n",
    "2. Add a [dropout layer](https://keras.io/api/layers/core_layers/#dropout) after the pooling layer. Set the dropout rate to 50%.\n",
    "3. Make sure to note from the documentation above that the rate specified for dropout in Keras is the opposite of TensorFlow! TensorFlow uses the probability to keep nodes, while Keras uses the probability to drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load pickled data\n",
    "with open('small_train_traffic.p', mode='rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "X_train, y_train = data['features'], data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build Convolutional Pooling Neural Network with Dropout in Keras Here\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), padding = 'valid', activation = 'relu', input_shape = (32, 32, 3)))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(5, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/3\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4626 - acc: 0.8250 - val_loss: 0.3302 - val_acc: 0.8500\n",
      "Epoch 2/3\n",
      "80/80 [==============================] - 0s 974us/step - loss: 0.4252 - acc: 0.8125 - val_loss: 0.2398 - val_acc: 0.8500\n",
      "Epoch 3/3\n",
      "80/80 [==============================] - 0s 797us/step - loss: 0.3315 - acc: 0.8000 - val_loss: 0.1874 - val_acc: 0.8500\n"
     ]
    }
   ],
   "source": [
    "# compile and fit model\n",
    "model.compile('adam', 'categorical_crossentropy', ['acc'])\n",
    "history = model.fit(X_normalized, y_one_hot, epochs=3, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice work!\n",
      "Looks good!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "### Be sure to run all cells above before running this cell ###\n",
    "import grader_dropout as grader\n",
    "\n",
    "try:\n",
    "    grader.run_grader(model, history)\n",
    "except Exception as err:\n",
    "    print(str(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "Once you've picked out your best model, it's time to test it!\n",
    "\n",
    "1. Try to get the highest validation accuracy possible. Feel free to use all the previous concepts and train for as many epochs as needed.\n",
    "2. Select your best model and train it one more time.\n",
    "3. Use the test data and the [Keras](https://keras.io/api/models/model/#evaluate) `evaluate()` method to see how well the model does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load pickled data\n",
    "with open('small_train_traffic.p', mode='rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Data\n",
    "X_train, y_train = data['features'], data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Final Test Neural Network in Keras Here\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 1.4108 - accuracy: 0.2375 - val_loss: 0.8194 - val_accuracy: 0.4500\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 0s 781us/step - loss: 0.9024 - accuracy: 0.5125 - val_loss: 0.5821 - val_accuracy: 0.7500\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 0s 822us/step - loss: 0.6767 - accuracy: 0.6875 - val_loss: 0.4548 - val_accuracy: 0.8500\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.5189 - accuracy: 0.8500 - val_loss: 0.3337 - val_accuracy: 0.8500\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.4081 - accuracy: 0.8000 - val_loss: 0.2367 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 0s 806us/step - loss: 0.3082 - accuracy: 0.9375 - val_loss: 0.2035 - val_accuracy: 0.8500\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 0s 835us/step - loss: 0.2633 - accuracy: 0.8875 - val_loss: 0.1988 - val_accuracy: 0.8500\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 0s 856us/step - loss: 0.2855 - accuracy: 0.8125 - val_loss: 0.1490 - val_accuracy: 0.9500\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 0s 867us/step - loss: 0.2638 - accuracy: 0.8500 - val_loss: 0.1194 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 0s 897us/step - loss: 0.1747 - accuracy: 0.9500 - val_loss: 0.1068 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# compile and fit the model\n",
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "history = model.fit(X_normalized, y_one_hot, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "20/20 [==============================] - 0s 150us/step\n",
      "loss: 0.18307363986968994\n",
      "accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# evaluate model against the test data\n",
    "with open('small_test_traffic.p', 'rb') as f:\n",
    "    data_test = pickle.load(f)\n",
    "\n",
    "X_test = data_test['features']\n",
    "y_test = data_test['labels']\n",
    "\n",
    "# preprocess data\n",
    "X_normalized_test = np.array(X_test / 255.0 - 0.5 )\n",
    "y_one_hot_test = label_binarizer.fit_transform(y_test)\n",
    "\n",
    "print(\"Testing\")\n",
    "\n",
    "metrics = model.evaluate(X_normalized_test, y_one_hot_test)\n",
    "for metric_i in range(len(model.metrics_names)):\n",
    "    metric_name = model.metrics_names[metric_i]\n",
    "    metric_value = metrics[metric_i]\n",
    "    print('{}: {}'.format(metric_name, metric_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice, accuracy was 1.0\n",
      "Good Job, accuracy was above 90%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "### Be sure to run all cells above before running this cell ###\n",
    "import grader_testing as grader\n",
    "\n",
    "try:\n",
    "    grader.run_grader(metrics)\n",
    "except Exception as err:\n",
    "    print(str(err))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
